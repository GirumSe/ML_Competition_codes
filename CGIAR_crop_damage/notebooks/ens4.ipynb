{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7027067,"sourceType":"datasetVersion","datasetId":3963802}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from fastai.metrics import accuracy\nfrom fastai.optimizer import OptimWrapper\nfrom fastai.vision.all import *\nfrom PIL import Image\n\nfrom torch import optim\nimport torch.nn as nn\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom transformers import AdamW\nimport cv2\n\nimport gc\nimport glob\nimport inspect\nimport pandas as pd\nfrom concurrent.futures import ProcessPoolExecutor\nfrom functools import partial\n\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage import color, transform\nfrom sklearn.model_selection import StratifiedKFold\n\nimport warnings \nwarnings.filterwarnings('ignore')\nset_seed(3, reproducible=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-06T06:24:45.716390Z","iopub.execute_input":"2024-01-06T06:24:45.717439Z","iopub.status.idle":"2024-01-06T06:24:45.726546Z","shell.execute_reply.started":"2024-01-06T06:24:45.717405Z","shell.execute_reply":"2024-01-06T06:24:45.725543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn_path = '/kaggle/input/zindidata/images/images'\nfiles    = get_image_files(trn_path) ","metadata":{"execution":{"iopub.status.busy":"2024-01-06T06:24:49.661661Z","iopub.execute_input":"2024-01-06T06:24:49.662060Z","iopub.status.idle":"2024-01-06T06:25:12.134691Z","shell.execute_reply.started":"2024-01-06T06:24:49.662029Z","shell.execute_reply":"2024-01-06T06:25:12.133756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train            = pd.read_csv('/kaggle/input/zindidata/Train.csv')\nTest             = pd.read_csv('/kaggle/input/zindidata/Test.csv')\nSampleSubmission = pd.read_csv('/kaggle/input/zindidata/SampleSubmission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-06T06:25:21.175598Z","iopub.execute_input":"2024-01-06T06:25:21.176085Z","iopub.status.idle":"2024-01-06T06:25:21.280620Z","shell.execute_reply.started":"2024-01-06T06:25:21.176043Z","shell.execute_reply":"2024-01-06T06:25:21.279795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"damage = Train.damage.unique()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T06:25:24.354602Z","iopub.execute_input":"2024-01-06T06:25:24.354987Z","iopub.status.idle":"2024-01-06T06:25:24.368709Z","shell.execute_reply.started":"2024-01-06T06:25:24.354958Z","shell.execute_reply":"2024-01-06T06:25:24.367606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_HEIGHT = IMG_WIDTH = 224\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD = (0.229, 0.224, 0.225)\nINCEPTION_MEAN = INCEPTION_STD = (0.5, 0.5, 0.5)\n\n\nclass AlbumentationsTransform(RandTransform):\n    \"A transform handler for multiple `Albumentation` transforms\"\n    split_idx, order = None, 2\n    def __init__(self, train_aug, valid_aug): store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n        \n        return aug_img\n\n\ndef get_train_transforms(mean_std):\n    augmentations = [\n        A.HorizontalFlip(p=.5),\n        A.VerticalFlip(p=.5),\n        A.RandomRotate90(p=.5),\n        A.ShiftScaleRotate(\n            shift_limit=0.2, scale_limit=0.3, \n            rotate_limit=45, border_mode=0, p=.4\n        ),\n        A.RandomBrightnessContrast(brightness_limit=(-0.15,0.2), contrast_limit=(-0.1, 0.1), p=0.5),\n        A.Resize(IMG_HEIGHT, IMG_WIDTH),\n        A.Cutout(\n            max_h_size=int(IMG_HEIGHT*0.2),\n            max_w_size=int(IMG_WIDTH*0.2),\n            num_holes=2,\n            p=.4,\n        ),\n    ]\n    if mean_std=='imagenet':\n        augmentations.append(A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD))\n    elif mean_std=='inception':\n        augmentations.append(A.Normalize(mean=INCEPTION_MEAN, std=INCEPTION_STD))\n    else:\n        augmentations.append(A.Normalize(mean=0, std=1))\n\n    augmentations.append(ToTensorV2())\n    return A.Compose(augmentations)\n\n\ndef get_valid_transforms(mean_std):\n    augmentations = [A.Resize(IMG_HEIGHT, IMG_WIDTH)]\n    if mean_std=='imagenet':\n        augmentations.append(A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD))\n    elif mean_std=='inception':\n        augmentations.append(A.Normalize(mean=INCEPTION_MEAN, std=INCEPTION_STD))\n    else:\n        augmentations.append(A.Normalize(mean=0, std=1))\n\n    augmentations.append(ToTensorV2())\n    return A.Compose(augmentations)\n\ndef get_item_tfms(mean_std='imagenet'):\n    return [AlbumentationsTransform(get_train_transforms(mean_std), get_valid_transforms(mean_std))]","metadata":{"execution":{"iopub.status.busy":"2024-01-06T06:25:28.558162Z","iopub.execute_input":"2024-01-06T06:25:28.558514Z","iopub.status.idle":"2024-01-06T06:25:28.575180Z","shell.execute_reply.started":"2024-01-06T06:25:28.558488Z","shell.execute_reply":"2024-01-06T06:25:28.574171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(arch, item, batch, epoch=7):\n    dblock = DataBlock(blocks = (ImageBlock, CategoryBlock(vocab=damage)),\n                       get_x = ColReader('filename', pref = '/kaggle/input/zindidata/images/images/'),\n                       get_y = ColReader('damage'),\n                       splitter = RandomSplitter(valid_pct = 0.2, seed = 3),\n                       item_tfms = item, #Resize(320, method = 'squish'),\n                       batch_tfms = batch, #aug_transforms(size = 128, min_scale = 0.75)\n                      )\n\n    dls = dblock.dataloaders(Train)\n    learn = vision_learner(dls, arch, loss_func = nn.CrossEntropyLoss(), metrics=accuracy).to_fp16()\n    learn.fine_tune(epoch, 0.018)  \n    dls.rng.seed(3)\n    return learn","metadata":{"execution":{"iopub.status.busy":"2024-01-06T06:25:35.916297Z","iopub.execute_input":"2024-01-06T06:25:35.917337Z","iopub.status.idle":"2024-01-06T06:25:35.926211Z","shell.execute_reply.started":"2024-01-06T06:25:35.917290Z","shell.execute_reply":"2024-01-06T06:25:35.924858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn1 = train('convit_small.fb_in1k', get_item_tfms(mean_std='inception')\n               , aug_transforms(mult=0.9, do_flip=True, flip_vert=True,\n                 max_rotate=33.2, min_zoom=0.6,\n                 max_zoom=2, max_lighting=0.4,\n                 max_warp=0.5, p_affine=0.6, size = 224, min_scale= 0.7)\n               , epoch=10)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T06:25:46.286919Z","iopub.execute_input":"2024-01-06T06:25:46.287342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn2 = train('convnext_small.in12k', get_item_tfms(mean_std='inception'), aug_transforms(mult=0.9, do_flip=True, flip_vert=True,\n                 max_rotate=13.2, min_zoom=0.6,\n                 max_zoom=1.9, max_lighting=0.4,\n                 max_warp=0.4, p_affine=0.60, size = 224, min_scale= 0.7), epoch=10)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T15:47:01.688440Z","iopub.execute_input":"2023-12-16T15:47:01.688805Z","iopub.status.idle":"2023-12-16T15:48:13.284658Z","shell.execute_reply.started":"2023-12-16T15:47:01.688775Z","shell.execute_reply":"2023-12-16T15:48:13.282984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn3 = train('deit_small_distilled_patch16_224.fb_in1k', get_item_tfms(mean_std='inception'), aug_transforms(mult=0.9, do_flip=True, flip_vert=True,\n                 max_rotate=13.2, min_zoom=0.6,\n                 max_zoom=1.9, max_lighting=0.4,\n                 max_warp=0.4, p_affine=0.52, size = 224, min_scale= 0.7), epoch=10)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T15:50:34.092584Z","iopub.execute_input":"2023-12-16T15:50:34.093482Z","iopub.status.idle":"2023-12-16T15:51:02.456671Z","shell.execute_reply.started":"2023-12-16T15:50:34.093444Z","shell.execute_reply":"2023-12-16T15:51:02.454699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid = learn1.dls.valid\npreds1 , targets = learn1.tta(dl=valid)\naccuracy(preds1 , targets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds1 = F.softmax(preds1, dim=1)\npreds1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid = learn2.dls.valid\npreds2 , targets = learn2.tta(dl=valid)\naccuracy(preds2 , targets)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds2 = F.softmax(preds2, dim=1)\npreds2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid = learn3.dls.valid\npreds3 , targets = learn3.tta(dl=valid)\naccuracy(preds3 , targets)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds3 = F.softmax(preds3, dim=1)\npreds3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_preds = (preds1 + preds2 + preds3) / 3\naccuracy(ensemble_preds , targets)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dl = learn1.dls.test_dl('/kaggle/input/zindidata/images/images/' + Test['filename'])\npreds1 , _ = learn1.tta(dl=test_dl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds1 = F.softmax(preds1, dim=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sf = pd.DataFrame({\n    \n    'ID': Test['ID'],\n    'DR': preds1[:, 0].squeeze().numpy(),\n    'G' : preds1[:, 1].squeeze().numpy(),\n    'ND': preds1[:, 2].squeeze().numpy(),\n    'WD': preds1[:, 3].squeeze().numpy(),\n    'other': preds1[:, 4].squeeze().numpy(),\n})\nsubmission_sf.to_csv('convit4.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dl = learn2.dls.test_dl('/kaggle/input/zindidata/images/images/' + Test['filename'])\npreds2 , _ = learn2.tta(dl=test_dl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds2 = F.softmax(preds2, dim=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sf = pd.DataFrame({\n    \n    'ID': Test['ID'],\n    'DR': preds2[:, 0].squeeze().numpy(),\n    'G' : preds2[:, 1].squeeze().numpy(),\n    'ND': preds2[:, 2].squeeze().numpy(),\n    'WD': preds2[:, 3].squeeze().numpy(),\n    'other': preds2[:, 4].squeeze().numpy(),\n})\nsubmission_sf.to_csv('convnext4.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dl = learn3.dls.test_dl('/kaggle/input/zindidata/images/images/' + Test['filename'])\npreds3 , _ = learn3.tta(dl=test_dl)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds3 = F.softmax(preds3, dim=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sf = pd.DataFrame({\n    \n    'ID': Test['ID'],\n    'DR': preds3[:, 0].squeeze().numpy(),\n    'G' : preds3[:, 1].squeeze().numpy(),\n    'ND': preds3[:, 2].squeeze().numpy(),\n    'WD': preds3[:, 3].squeeze().numpy(),\n    'other': preds3[:, 4].squeeze().numpy(),\n})\nsubmission_sf.to_csv('deit_small4.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens_preds = (preds1 + preds2 + preds3) / 3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sf = pd.DataFrame({\n    'ID': Test['ID'],\n    'DR': ens_preds[:, 0].squeeze().numpy(),\n    'G' : ens_preds[:, 1].squeeze().numpy(),\n    'ND': ens_preds[:, 2].squeeze().numpy(),\n    'WD': ens_preds[:, 3].squeeze().numpy(),\n    'other': ens_preds[:, 4].squeeze().numpy(),\n})\nsubmission_sf.to_csv('ens4.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sf","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}