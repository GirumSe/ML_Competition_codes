{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hnN4Upki45Lp"
      },
      "source": [
        "IMPORT\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "if you want want to use the notebook in google colabs you can use the code below, but if you want to use it locally you can skip the first step to mount the google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l2VlFP05DIj",
        "outputId": "a0809e33-7e4e-41d7-ff44-c00298effc04"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "petroleum data scraped from https://www.energy.gov.za/files/esources/petroleum/petroleum_arch.html\n",
        "lending data scraped from https://www.fnb.co.za/rates/LendingRates.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Vm30nG4r45Ls"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
        "\n",
        "pd.options.display.max_columns = 2000\n",
        "pd.options.display.max_rows = 2000\n",
        "\n",
        "#put the your data folder path here\n",
        "path = '/content/drive/MyDrive/submit'\n",
        "cpi = pd.read_csv('CPI_Historic_Values_Zindi_May_23.csv')\n",
        "petrol = pd.read_csv('petrolem.csv')\n",
        "lending = pd.read_csv('historical_prime_lending_rates.csv')\n",
        "lending = lending.ffill()\n",
        "seed = 3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o1q9A4d345Lu"
      },
      "source": [
        "PIVOTING THE DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Z6OlcGqC45Lv"
      },
      "outputs": [],
      "source": [
        "cpi_pivot = cpi.pivot(index = 'Month', columns = 'Category', values = 'Value').reset_index()#changing from a long format to a wide format,\n",
        "cpi_pivot['Month'] = pd.to_datetime(cpi_pivot['Month'])\n",
        "cpi_pivot = cpi_pivot.sort_values(\"Month\").reset_index(drop=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zOX45dML45Lv"
      },
      "source": [
        "ADDING JUNE'S DATA MANUALLY FROM https://www.statssa.gov.za/publications/P0141/P0141June2023.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "hzDvFmZb45Lw"
      },
      "outputs": [],
      "source": [
        "date_str = '2023-06-30'\n",
        "date_obj = pd.to_datetime(date_str)\n",
        "new_row = pd.DataFrame({'Month': [date_obj]})\n",
        "cpi_pivot = pd.concat([cpi_pivot, new_row]).reset_index(drop=True)\n",
        "cpi_of_june = [110.9, 104.3, 99.6, 110.4, 118.3, 109.8, 110.8, 107.7, 105.4, 109.6, 105.3, 110.0, 112.3]\n",
        "\n",
        "for i, col in enumerate(cpi_pivot.columns[1:]):\n",
        "    cpi_pivot.at[17, col] = cpi_of_june[i]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cB5a4Ui445Lw"
      },
      "source": [
        "ADD THE july ROW\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Oe85NUZf45Lx"
      },
      "outputs": [],
      "source": [
        "date_str = '2023-07-31'\n",
        "date_obj = pd.to_datetime(date_str)\n",
        "new_row = pd.DataFrame({'Month': [date_obj]})\n",
        "cpi_pivot = pd.concat([cpi_pivot, new_row]).reset_index(drop=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IeXiLFX245Lx"
      },
      "source": [
        "FEATURE ENGINNERING\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the only feature i used is a 5 times lagging features of all the month's cpi's. nothing fancy other than that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NEbdhUtZ45Ly"
      },
      "outputs": [],
      "source": [
        "feats_to_lag = cpi_pivot.columns[1:].to_list()\n",
        "for col in feats_to_lag:\n",
        "    for i in range(1,5):\n",
        "        cpi_pivot[f'prev_{i}_month_{col}'] = cpi_pivot[col].shift(i)\n",
        "columns = list(cpi_pivot.columns)\n",
        "columns = [item for item in columns if \"Transport\" not in item]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add petrol data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "petrol['Month'] = pd.to_datetime(petrol['Month'])\n",
        "petrol = petrol.sort_values(\"Month\").reset_index(drop=True)\n",
        "feats_to_lag = petrol.columns[1:].to_list()\n",
        "for col in feats_to_lag:\n",
        "    for i in range(1,5):\n",
        "        petrol[f'prev_{i}_month_{col}'] = petrol[col].shift(i)\n",
        "start_date = pd.to_datetime('2022-01-31')\n",
        "end_date = pd.to_datetime('2023-07-31')\n",
        "petrol = petrol[(petrol['Month'] >= start_date) & (petrol['Month'] <= end_date)]\n",
        "cpi_pivot = pd.merge(cpi_pivot, petrol, on='Month', suffixes=('_df1', '_df2'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "lending['Interest_per_annum'] = lending['Interest_per_annum'].str.rstrip('%').astype(float).astype(int)\n",
        "lending['Month'] = pd.to_datetime(lending['Month'])\n",
        "lending = lending.sort_values(\"Month\").reset_index(drop=True)\n",
        "feats_to_lag = lending.columns[1:].to_list()\n",
        "for col in feats_to_lag:\n",
        "    for i in range(1,5):\n",
        "        lending[f'prev_{i}_month_{col}'] = lending[col].shift(i)\n",
        "start_date = pd.to_datetime('2022-01-31')\n",
        "end_date = pd.to_datetime('2023-07-31')\n",
        "lending = lending[(lending['Month'] >= start_date) & (lending['Month'] <= end_date)]\n",
        "cpi_pivot = pd.merge(cpi_pivot, lending, on='Month', suffixes=('_df1', '_df2'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "petcol = list(petrol.columns)\n",
        "search_strings = [\"petrol95\" ,\"randuS_exchenge\" ]\n",
        "petcol = [item for item in petcol if all(search_str not in item for search_str in search_strings)]\n",
        "petcol = petcol[1:]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "niEeRFZd45Ly"
      },
      "source": [
        "HANDLE MISSING DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "32ifNu-J45Lz"
      },
      "outputs": [],
      "source": [
        "cpi_pivot = cpi_pivot.drop(0)\n",
        "cpi_pivot = cpi_pivot.bfill()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5zm2DLYb45Lz"
      },
      "source": [
        "TRAIN AND VALIDATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64xB9pYu45Lz",
        "outputId": "3dcb1e58-9d2a-4d6d-a272-44b5314396b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((17, 101), (1, 101), (16, 101), (1, 101))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = cpi_pivot[cpi_pivot['Month'] != \"2023-07-31\"]\n",
        "test = cpi_pivot[cpi_pivot['Month'] == \"2023-07-31\"]\n",
        "\n",
        "training_set = train[train['Month']!= '2023-06-30']\n",
        "validation_set = train[train['Month']== '2023-06-30']\n",
        "\n",
        "train.shape, test.shape, training_set.shape, validation_set.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K3T9Bybk45L0"
      },
      "source": [
        "MODELING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWcNNdxx45L1",
        "outputId": "b7b5fc68-1394-4939-cdde-434bbeabd28e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE of Lasso Regression for Alcoholic beverages and tobacco: 0.2034060784736056\n",
            "RMSE of Lasso Regression for Clothing and footwear: 0.23752717206255625\n",
            "RMSE of Lasso Regression for Communication: 0.09375\n",
            "RMSE of Lasso Regression for Education: 0.0032400410476611796\n",
            "RMSE of Lasso Regression for Food and non-alcoholic beverages: 1.855068645641282\n",
            "RMSE of Lasso Regression for Headline_CPI: 0.5112470304621581\n",
            "RMSE of Lasso Regression for Health: 1.352394156574249\n",
            "RMSE of Lasso Regression for Household contents and services: 1.3777526144050398\n",
            "RMSE of Lasso Regression for Housing and utilities: 0.8384453090201021\n",
            "RMSE of Lasso Regression for Miscellaneous goods and services: 0.5989762610143003\n",
            "RMSE of Lasso Regression for Recreation and culture: 0.918526676787593\n",
            "RMSE of Lasso Regression for Restaurants and hotels : 0.3152614906908724\n",
            "RMSE of Lasso Regression for Transport: 0.06692962646484091\n",
            "Average RMSE of Lasso Regression: 0.644040392511097\n"
          ]
        }
      ],
      "source": [
        "target_cols = ['Alcoholic beverages and tobacco', 'Clothing and footwear',\n",
        "       'Communication', 'Education', 'Food and non-alcoholic beverages',\n",
        "       'Headline_CPI', 'Health', 'Household contents and services',\n",
        "       'Housing and utilities', 'Miscellaneous goods and services',\n",
        "       'Recreation and culture', 'Restaurants and hotels ', 'Transport']\n",
        "\n",
        "#if you add additional data sources that have no value in the predicting month , drop it, now that you have their lags\n",
        "features= [col for col in train.columns if col not in target_cols + ['Month']]\n",
        "featurest= [col for col in train.columns if col not in columns + ['Transport']]\n",
        "\n",
        "X_train = training_set[features]\n",
        "X_traint = training_set[featurest]\n",
        "y_train = training_set[target_cols]\n",
        "\n",
        "X_val = validation_set[features]\n",
        "X_valt = validation_set[featurest]\n",
        "y_val = validation_set[target_cols]\n",
        "\n",
        "l_models = {}\n",
        "\n",
        "y_predl = []\n",
        "\n",
        "rmsel_dict = {} \n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#training\n",
        "for target_col in target_cols:\n",
        "    if target_col == \"Transport\":\n",
        "        #l_model = Lasso(alpha=0.1, random_state=seed)\n",
        "        l_model = XGBRegressor(seed=seed)\n",
        "        X_train_scaled = scaler.fit_transform(X_traint)\n",
        "\n",
        "        l_model.fit(X_train_scaled, y_train[target_col])\n",
        "\n",
        "        l_models[target_col] = l_model\n",
        "        \n",
        "        l_model = l_models[target_col]\n",
        "\n",
        "        X_val_scaled = scaler.transform(X_valt)\n",
        "\n",
        "        y_pred_coll = l_model.predict(X_val_scaled)\n",
        "\n",
        "        rmsel_col = np.sqrt(mean_squared_error(y_pred_coll, y_val[target_col]))\n",
        "        rmsel_dict[target_col] = rmsel_col \n",
        "\n",
        "        y_predl.append(y_pred_coll)\n",
        "    else:\n",
        "        l_model = Lasso(alpha=0.1, random_state=seed)\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "        l_model.fit(X_train_scaled, y_train[target_col])\n",
        "\n",
        "        l_models[target_col] = l_model\n",
        "        \n",
        "        l_model = l_models[target_col]\n",
        "\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "        y_pred_coll = l_model.predict(X_val_scaled)\n",
        "\n",
        "        rmsel_col = np.sqrt(mean_squared_error(y_pred_coll, y_val[target_col]))\n",
        "        rmsel_dict[target_col] = rmsel_col \n",
        "\n",
        "        y_predl.append(y_pred_coll)\n",
        "\n",
        "# scoring\n",
        "y_predl = np.array(y_predl).T\n",
        "y_predl[:,5][0] = ((6.26 * y_predl[:,0][0]) + (3.65 * y_predl[:,1][0]) + (2.42 * y_predl[:,2][0]) \n",
        "                   + (2.62 * y_predl[:,3][0]) + (17.14 * y_predl[:,4][0]) + (1.44 * y_predl[:,6][0]) + \n",
        "                   (4.37 * y_predl[:,7][0]) \n",
        "                   + (24.49 * y_predl[:,8][0]) + (14.81 * y_predl[:,9][0]) + (5.2 * y_predl[:,10][0]) + \n",
        "                   (3.25 * y_predl[:,11][0]) + (14.35 * y_predl[:,12][0]))/100\n",
        "\n",
        "dfl = pd.DataFrame({'y_pred': y_predl.flatten(), 'y_val': y_val.values.flatten()})\n",
        "\n",
        "# Print RMSE for each target column\n",
        "for target_col in target_cols:\n",
        "    print(f'RMSE of Lasso Regression for {target_col}: {rmsel_dict[target_col]}')\n",
        "\n",
        "# Calculate the average RMSE across all target columns\n",
        "average_rmse = np.mean(list(rmsel_dict.values()))\n",
        "print(f'Average RMSE of Lasso Regression: {average_rmse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE for Alcoholic beverages and tobacco: -0.4978647740247766\n",
            "RMSE for Clothing and footwear: -0.2183598730725862\n",
            "RMSE for Communication: 0.18823529411763218\n",
            "RMSE for Education: 0.27408521636726846\n",
            "RMSE for Food and non-alcoholic beverages: -0.23427233386446744\n",
            "RMSE for Headline_CPI: -0.3324382686637932\n",
            "RMSE for Health: -0.29254809357426836\n",
            "RMSE for Household contents and services: -0.11331912097216446\n",
            "RMSE for Housing and utilities: -0.7631320973497964\n",
            "RMSE for Miscellaneous goods and services: 0.018624071199482728\n",
            "RMSE for Recreation and culture: -0.2618507558022003\n",
            "RMSE for Restaurants and hotels : 0.052578421557896604\n",
            "RMSE for Transport: -0.19887695312499432\n",
            "Average RMSE for all columns: 0.3238624759808155\n"
          ]
        }
      ],
      "source": [
        "X_train = train[features]\n",
        "X_traint = train[featurest]\n",
        "y_train = train[target_cols]\n",
        "\n",
        "X_val = test[features]\n",
        "X_valt = test[featurest]\n",
        "y_val = test[target_cols]\n",
        "\n",
        "l_models = {}\n",
        "\n",
        "y_predl = []\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#training\n",
        "for target_col in target_cols:\n",
        "    if target_col == \"Transport\":\n",
        "        #l_model = Lasso(alpha=0.1, random_state=seed)\n",
        "        l_model = XGBRegressor(seed=seed)\n",
        "        X_train_scaled = scaler.fit_transform(X_traint)\n",
        "\n",
        "        l_model.fit(X_train_scaled, y_train[target_col])\n",
        "\n",
        "        l_models[target_col] = l_model\n",
        "        l_model = l_models[target_col]\n",
        "\n",
        "        X_val_scaled = scaler.transform(X_valt)\n",
        "\n",
        "        y_pred_coll = l_model.predict(X_val_scaled)\n",
        "\n",
        "        y_predl.append(y_pred_coll)\n",
        "    else:\n",
        "        l_model = Lasso(alpha=0.1, random_state=seed)\n",
        "\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "        l_model.fit(X_train_scaled, y_train[target_col])\n",
        "\n",
        "        l_models[target_col] = l_model\n",
        "        l_model = l_models[target_col]\n",
        "\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "        y_pred_coll = l_model.predict(X_val_scaled)\n",
        "\n",
        "        y_predl.append(y_pred_coll)\n",
        "\n",
        "july = [111.5, 104.5, 99.5, 110.4, 118.5, 110.8, 110.6, 108.2 , 108.4, 109.9, 105.5, 110, 112.6]\n",
        "y_predl = np.array(y_predl).T\n",
        "y_predl[:,5][0] = ((6.26 * y_predl[:,0][0]) + (3.65 * y_predl[:,1][0]) + (2.42 * y_predl[:,2][0]) \n",
        "                   + (2.62 * y_predl[:,3][0]) + (17.14 * y_predl[:,4][0]) + (1.44 * y_predl[:,6][0]) + \n",
        "                   (4.37 * y_predl[:,7][0]) \n",
        "                   + (24.49 * y_predl[:,8][0]) + (14.81 * y_predl[:,9][0]) + (5.2 * y_predl[:,10][0]) + \n",
        "                   (3.25 * y_predl[:,11][0]) + (14.35 * y_predl[:,12][0]))/100\n",
        "july = np.array(july).T\n",
        "\n",
        "#print(f'prediction of Lasso Regression: {y_predl}')\n",
        "rmse_values = {}\n",
        "\n",
        "for i, target_col in enumerate(target_cols):\n",
        "    y_pred_col = y_predl[:, i][0] # Predictions for the current target column\n",
        "    july_col = july[i]\n",
        "    rmse_col = y_pred_col - july_col \n",
        "    rmse_values[target_col] = rmse_col  # Store RMSE value in the dictionary\n",
        "\n",
        "    print(f'RMSE for {target_col}: {rmse_col}')\n",
        "july = [[111.5], [104.5], [99.5], [110.4], [118.5], [110.8], [110.6], [108.2] , [108.4], [109.9], [105.5], [110], [112.6]]\n",
        "july = np.array(july).T\n",
        "# Calculate the average RMSE across all target columns\n",
        "average_rmse = np.sqrt(mean_squared_error(y_predl, july))\n",
        "print(f'Average RMSE for all columns: {average_rmse}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ieArthL745L7"
      },
      "source": [
        "SUBMITION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR0JhdNv45L7"
      },
      "outputs": [],
      "source": [
        "def prepSub(y_pred:list, target_cols: list, test, prefix:str):\n",
        "    sub_df = pd.DataFrame(y_pred, columns=target_cols)\n",
        "    sub_df['Month'] = test['Month']\n",
        "\n",
        "    sub_df.set_index('Month', inplace=True)\n",
        "    sub_df.columns = [prefix+'_' + col.lower().replace('_', ' ').strip() for col in sub_df.columns]\n",
        "    sub_df.rename(columns= {f\"{prefix}_headline cpi\": f\"{prefix}_headline CPI\"}, inplace=True)\n",
        "\n",
        "    sub_df = pd.melt(sub_df.reset_index(), id_vars= ['Month'], var_name= 'ID', value_name= 'Value')\n",
        "\n",
        "    return sub_df[['ID', 'Value']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0vrq5hQ45L8"
      },
      "outputs": [],
      "source": [
        "sub = prepSub(y_predl, target_cols, test, 'July')\n",
        "sub.to_csv(f'out/lasso_with_lag5_historic_petroledl7.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
